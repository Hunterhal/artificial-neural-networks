{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MLP - IRIS Dataset\n",
    "\n",
    "## IRIS Dataset\n",
    "\n",
    "IRIS dataset is downloaded from <https://archive.ics.uci.edu/ml/datasets/iris>.\n",
    "\n",
    "The dataset consists of three classes and four features. Each class has 50 samples and the dataset has 150 samples in total. \n",
    "The is in text format every line has input feature and label. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(120, 5) (30, 5)\n[5.8 4.  1.2 0.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "#First open and read the file\n",
    "f = open(\"iris.data\", \"r\")\n",
    "data = f.read()\n",
    "#Split each line and create the list\n",
    "data_list = data.split(\"\\n\")\n",
    "\n",
    "#Seperate each data\n",
    "data_seperate = []\n",
    "dataset = []\n",
    "for i in range(len(data_list)):\n",
    "    dataset.append([])\n",
    "    data_seperate = data_list[i].split(\",\")\n",
    "    x1 = float(data_seperate[0])\n",
    "    x2 = float(data_seperate[1])\n",
    "    x3 = float(data_seperate[2])\n",
    "    x4 = float(data_seperate[3])\n",
    "\n",
    "    if data_seperate[4] == \"Iris-virginica\":\n",
    "        y = 2\n",
    "    elif data_seperate[4] == \"Iris-versicolor\":\n",
    "        y = 1\n",
    "    elif data_seperate[4] == \"Iris-setosa\":\n",
    "        y = 0\n",
    "\n",
    "    dataset[i].append([x1, x2, x3, x4, y])\n",
    "\n",
    "#Now we will seperate 40 of each class to train set and remaining 10 to test set, we will also shuffle the selections\n",
    "train = int(40)\n",
    "dataset = np.array(dataset, dtype=np.float32).reshape(150, 5)\n",
    "cls1 = np.arange(50, dtype=np.int)\n",
    "random.shuffle(cls1)\n",
    "cls1_train = cls1[0: train]\n",
    "cls1_test = cls1[train:]\n",
    "\n",
    "cls2 = np.arange(50, 100, dtype=np.int)\n",
    "random.shuffle(cls2)\n",
    "cls2_train = cls2[0: train]\n",
    "cls2_test = cls2[train:]\n",
    "\n",
    "cls3 = np.arange(100, 150, dtype=np.int)\n",
    "random.shuffle(cls3)\n",
    "cls3_train = cls3[0: train]\n",
    "cls3_test = cls3[train:]\n",
    "\n",
    "#Lastly birng all the data\n",
    "dataset_train = dataset[np.concatenate((cls1_train, cls2_train, cls3_train)), :]\n",
    "dataset_test = dataset[np.concatenate((cls1_test, cls2_test, cls3_test)), :]\n",
    "print(dataset_train.shape, dataset_test.shape)\n",
    "print(dataset_train[0])\n"
   ]
  },
  {
   "source": [
    "### Utility Functions\n",
    "\n",
    "Now as outputs we have numbers 0 1 2, but the outputs of the network will be 0 0 1 or 0.5 0.4 0.1 we need to vectorize the labels\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.]\n [0.]\n [0.]]\n[[0.]\n [1.]\n [0.]]\n[[0.]\n [0.]\n [1.]]\n[1]\n[2]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_vector(labels):\n",
    "    result = np.zeros((3, 1))\n",
    "    result[labels, 0] = 1\n",
    "    return result\n",
    "\n",
    "print(labels_to_vector([0]))\n",
    "print(labels_to_vector([1]))\n",
    "print(labels_to_vector([2]))\n",
    "\n",
    "def vector_to_labels(labels):\n",
    "    return np.array([np.argmax(labels)])\n",
    "\n",
    "print(vector_to_labels([0.1, 0.5, 0.3]))\n",
    "print(vector_to_labels([0, 0, 1]))\n",
    "\n",
    "def mean_square_error(ground_truth, desired):\n",
    "    temp = np.square(ground_truth - desired)\n",
    "    temp = np.mean( temp )\n",
    "    return temp"
   ]
  },
  {
   "source": [
    "## MLP \n",
    "\n",
    "Redefine to solve this problem MLP with 4 inputs, 20 neurons, 10 neurons, and 3 output neurons. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "input_dimension = 4\n",
    "input_data = dataset_train[0][0:-1].reshape(-1, 1)\n",
    "ground_truth = labels_to_vector( int(dataset_train[0][-1]) )\n",
    "\n",
    "layer_0 = 20\n",
    "layer_1 = 10\n",
    "layer_out = 3\n",
    "\n",
    "#Keep in mind the bias weights, all the weights are sampled from uniform distribution between 0 and 1. The substraction makes it -0.5 and 0.5.\n",
    "weights_0 = np.random.rand(layer_0, input_dimension + 1) - 0.5\n",
    "weights_1 = np.random.rand(layer_1, layer_0 + 1) - 0.5\n",
    "weights_out = np.random.rand(layer_out, layer_1 + 1) - 0.5\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 48,
   "outputs": []
  },
  {
   "source": [
    "## Training Loop\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Training MSE: 0.204330, Test MSE: 0.034479\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  0 10]\n",
      " [ 0  0 10]]\n",
      "Epoch: 1, Training MSE: 0.126935, Test MSE: 0.030558\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  0 10]\n",
      " [ 0  0 10]]\n",
      "Epoch: 2, Training MSE: 0.117101, Test MSE: 0.029878\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  7  3]]\n",
      "Epoch: 3, Training MSE: 0.112523, Test MSE: 0.026729\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  7  3]\n",
      " [ 0  0 10]]\n",
      "Epoch: 4, Training MSE: 0.102544, Test MSE: 0.025412\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  1  9]\n",
      " [ 0  0 10]]\n",
      "Epoch: 5, Training MSE: 0.096649, Test MSE: 0.024853\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  3  7]\n",
      " [ 0  0 10]]\n",
      "Epoch: 6, Training MSE: 0.091744, Test MSE: 0.021288\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  1  9]]\n",
      "Epoch: 7, Training MSE: 0.085260, Test MSE: 0.020202\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 8, Training MSE: 0.083425, Test MSE: 0.021017\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  4  6]]\n",
      "Epoch: 9, Training MSE: 0.072300, Test MSE: 0.018553\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  5  5]\n",
      " [ 0  0 10]]\n",
      "Epoch: 10, Training MSE: 0.069900, Test MSE: 0.014932\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 11, Training MSE: 0.065640, Test MSE: 0.015271\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  7  3]\n",
      " [ 0  0 10]]\n",
      "Epoch: 12, Training MSE: 0.058305, Test MSE: 0.013766\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 13, Training MSE: 0.052656, Test MSE: 0.023210\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  5  5]]\n",
      "Epoch: 14, Training MSE: 0.047771, Test MSE: 0.012197\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  7  3]\n",
      " [ 0  0 10]]\n",
      "Epoch: 15, Training MSE: 0.046784, Test MSE: 0.010341\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 16, Training MSE: 0.042666, Test MSE: 0.009665\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 17, Training MSE: 0.040336, Test MSE: 0.009971\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 18, Training MSE: 0.041033, Test MSE: 0.008537\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 19, Training MSE: 0.036789, Test MSE: 0.017922\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  4  6]]\n",
      "Epoch: 20, Training MSE: 0.036515, Test MSE: 0.008090\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 21, Training MSE: 0.037772, Test MSE: 0.009152\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 22, Training MSE: 0.037757, Test MSE: 0.008272\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 23, Training MSE: 0.034530, Test MSE: 0.008261\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 24, Training MSE: 0.033922, Test MSE: 0.007714\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 25, Training MSE: 0.030775, Test MSE: 0.007409\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 26, Training MSE: 0.033031, Test MSE: 0.008405\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 27, Training MSE: 0.032249, Test MSE: 0.023054\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  4  6]]\n",
      "Epoch: 28, Training MSE: 0.032288, Test MSE: 0.011604\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 29, Training MSE: 0.031459, Test MSE: 0.007862\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 30, Training MSE: 0.031861, Test MSE: 0.008938\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 31, Training MSE: 0.034008, Test MSE: 0.007004\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 32, Training MSE: 0.028925, Test MSE: 0.006891\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 33, Training MSE: 0.031745, Test MSE: 0.006934\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 34, Training MSE: 0.031674, Test MSE: 0.007357\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 35, Training MSE: 0.027994, Test MSE: 0.007805\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 36, Training MSE: 0.023852, Test MSE: 0.009473\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 37, Training MSE: 0.024725, Test MSE: 0.012351\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 38, Training MSE: 0.029167, Test MSE: 0.007297\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 39, Training MSE: 0.034224, Test MSE: 0.007141\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 40, Training MSE: 0.028982, Test MSE: 0.010210\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 41, Training MSE: 0.031007, Test MSE: 0.006750\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 42, Training MSE: 0.025735, Test MSE: 0.006819\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 43, Training MSE: 0.026494, Test MSE: 0.010384\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 44, Training MSE: 0.029329, Test MSE: 0.008042\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 45, Training MSE: 0.026110, Test MSE: 0.008239\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 46, Training MSE: 0.026597, Test MSE: 0.008858\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 47, Training MSE: 0.030530, Test MSE: 0.006499\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 48, Training MSE: 0.024724, Test MSE: 0.006800\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 49, Training MSE: 0.025712, Test MSE: 0.007431\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 50, Training MSE: 0.026690, Test MSE: 0.006001\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 51, Training MSE: 0.029486, Test MSE: 0.006123\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 52, Training MSE: 0.026531, Test MSE: 0.011377\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 53, Training MSE: 0.025900, Test MSE: 0.007278\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 54, Training MSE: 0.025742, Test MSE: 0.005594\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 55, Training MSE: 0.023558, Test MSE: 0.005784\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 56, Training MSE: 0.026216, Test MSE: 0.007209\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 57, Training MSE: 0.025483, Test MSE: 0.007795\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 58, Training MSE: 0.024578, Test MSE: 0.005950\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 59, Training MSE: 0.026878, Test MSE: 0.006533\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 60, Training MSE: 0.025684, Test MSE: 0.005780\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 61, Training MSE: 0.027544, Test MSE: 0.005342\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 62, Training MSE: 0.024379, Test MSE: 0.011081\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 63, Training MSE: 0.024105, Test MSE: 0.005521\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 64, Training MSE: 0.023558, Test MSE: 0.008143\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 65, Training MSE: 0.022036, Test MSE: 0.009416\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 66, Training MSE: 0.025839, Test MSE: 0.006881\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "Epoch: 67, Training MSE: 0.023841, Test MSE: 0.008987\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 68, Training MSE: 0.027073, Test MSE: 0.005981\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 69, Training MSE: 0.026259, Test MSE: 0.005164\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 70, Training MSE: 0.021525, Test MSE: 0.005081\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 71, Training MSE: 0.025867, Test MSE: 0.006381\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 72, Training MSE: 0.026209, Test MSE: 0.005369\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 73, Training MSE: 0.026296, Test MSE: 0.005685\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 74, Training MSE: 0.023899, Test MSE: 0.006312\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 75, Training MSE: 0.022936, Test MSE: 0.006227\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 76, Training MSE: 0.024445, Test MSE: 0.006392\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 77, Training MSE: 0.025489, Test MSE: 0.005188\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 78, Training MSE: 0.020876, Test MSE: 0.005780\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 79, Training MSE: 0.021434, Test MSE: 0.005776\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 80, Training MSE: 0.022699, Test MSE: 0.005240\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 81, Training MSE: 0.022680, Test MSE: 0.006180\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 82, Training MSE: 0.021017, Test MSE: 0.004813\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 83, Training MSE: 0.019498, Test MSE: 0.004714\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 84, Training MSE: 0.022245, Test MSE: 0.005199\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 85, Training MSE: 0.023166, Test MSE: 0.004805\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 86, Training MSE: 0.019449, Test MSE: 0.004688\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 87, Training MSE: 0.022233, Test MSE: 0.005073\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 88, Training MSE: 0.025160, Test MSE: 0.005154\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Epoch: 89, Training MSE: 0.026063, Test MSE: 0.004677\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 90, Training MSE: 0.025174, Test MSE: 0.004847\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 91, Training MSE: 0.022366, Test MSE: 0.010241\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 92, Training MSE: 0.023885, Test MSE: 0.004825\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 93, Training MSE: 0.020304, Test MSE: 0.005121\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 94, Training MSE: 0.021973, Test MSE: 0.004998\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 95, Training MSE: 0.023661, Test MSE: 0.004648\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 96, Training MSE: 0.021150, Test MSE: 0.004582\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Epoch: 97, Training MSE: 0.022863, Test MSE: 0.006749\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  9]]\n",
      "Epoch: 98, Training MSE: 0.024938, Test MSE: 0.009624\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "Epoch: 99, Training MSE: 0.024745, Test MSE: 0.005816\n",
      "Confusion matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 100 #Number of maximum epochs\n",
    "lr = 1e-2\n",
    "\n",
    "mse_train = [] #Buffer for error\n",
    "mse_test = []\n",
    "for epoch in range(max_epoch):\n",
    "    mse_epoch = 0\n",
    "    #Train loop\n",
    "    #Shuffle the indices\n",
    "    indices = np.arange(len(dataset_train))\n",
    "    random.shuffle(indices)\n",
    "    for train_index in indices:\n",
    "        #Inference\n",
    "        input_data = dataset_train[train_index][0:-1].reshape(-1, 1)\n",
    "        ground_truth = labels_to_vector( int(dataset_train[train_index][-1]) )\n",
    "\n",
    "        input_0 = np.concatenate((input_data, np.ones((1,1))))\n",
    "        lin_comb_0 = np.matmul(weights_0, input_0) #v\n",
    "        output_0 = np.tanh(lin_comb_0) #y\n",
    "\n",
    "        #Add bias to output 0\n",
    "        input_1 = np.concatenate((output_0, np.ones((1,1))))\n",
    "\n",
    "        lin_comb_1 = np.matmul(weights_1, input_1) #v\n",
    "        output_1 = np.tanh(lin_comb_1) #y\n",
    "\n",
    "        #Add bias to output 1\n",
    "        input_out = np.concatenate((output_1, np.ones((1,1))))\n",
    "\n",
    "        lin_comb_out = np.matmul(weights_out, input_out) #v\n",
    "        output_out = np.tanh(lin_comb_out) #y\n",
    "\n",
    "        #Error\n",
    "        mse_epoch += mean_square_error(ground_truth, output_out)\n",
    "        error = ground_truth - output_out \n",
    "\n",
    "        #Backpropagation\n",
    "        local_gradient_out = error * -1 * (1 - output_out**2)\n",
    "\n",
    "        weight_out_temp = np.transpose(weights_out[:, :-1]) #no bias and transpose\n",
    "        temp1 = np.matmul(weight_out_temp, local_gradient_out)\n",
    "        local_gradient_1 = temp1 * (1 - output_1**2)\n",
    "\n",
    "        weight_1_temp = np.transpose(weights_1[:, :-1]) #no bias and transpose\n",
    "        temp0 = np.matmul(weight_1_temp, local_gradient_1)\n",
    "        local_gradient_0 = temp0 * (1 - output_0**2)\n",
    " \n",
    "        #Calculate derivatives\n",
    "        derivative_out = np.matmul(local_gradient_out, input_out.transpose())\n",
    "        derivative_1 = np.matmul(local_gradient_1, input_1.transpose())\n",
    "        derivative_0 = np.matmul(local_gradient_0, input_0.transpose())\n",
    "\n",
    "        #Weight update\n",
    "        weights_0 = weights_0 - lr * derivative_0\n",
    "        weights_1 = weights_1 - lr * derivative_1\n",
    "        weights_out = weights_out - lr * derivative_out\n",
    "    \n",
    "    mse_train.append(mse_epoch/len(dataset_train))\n",
    "\n",
    "    mse_epoch = 0\n",
    "    test_gt = np.array([])\n",
    "    test_pred = np.array([])\n",
    "    #Test loop\n",
    "    #Shuffle the indices\n",
    "    indices = np.arange(len(dataset_test))\n",
    "    random.shuffle(indices)\n",
    "    for test_index in indices:\n",
    "        #Inference\n",
    "        input_data = dataset_test[test_index][0:-1].reshape(-1, 1)\n",
    "        ground_truth = labels_to_vector( int(dataset_test[test_index][-1]) )\n",
    "\n",
    "        input_0 = np.concatenate((input_data, np.ones((1,1))))\n",
    "        lin_comb_0 = np.matmul(weights_0, input_0) #v\n",
    "        output_0 = np.tanh(lin_comb_0) #y\n",
    "\n",
    "        #Add bias to output 0\n",
    "        input_1 = np.concatenate((output_0, np.ones((1,1))))\n",
    "\n",
    "        lin_comb_1 = np.matmul(weights_1, input_1) #v\n",
    "        output_1 = np.tanh(lin_comb_1) #y\n",
    "\n",
    "        #Add bias to output 1\n",
    "        input_out = np.concatenate((output_1, np.ones((1,1))))\n",
    "\n",
    "        lin_comb_out = np.matmul(weights_out, input_out) #v\n",
    "        output_out = np.tanh(lin_comb_out) #y\n",
    "\n",
    "        #Error\n",
    "        mse_epoch += mean_square_error(ground_truth, output_out)\n",
    "\n",
    "        test_gt = np.concatenate( (test_gt, vector_to_labels(ground_truth)) )\n",
    "        test_pred = np.concatenate( (test_pred, vector_to_labels(output_out)) )\n",
    "    mse_test.append(mse_epoch/len(dataset_train))\n",
    "\n",
    "    mse_test.append(mse_epoch/len(dataset_train))\n",
    "    print(\"Epoch: %d, Training MSE: %f, Test MSE: %f\"%(epoch, mse_train[-1], mse_test[-1]))\n",
    "\n",
    "    cm = confusion_matrix(test_gt, test_pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    #End condition\n",
    "    if(mse_test[-1] < 0.003):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "99 100\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (99,) and (100,)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-14f4e6b7652f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     return gca().plot(\n\u001b[0;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2795\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (99,) and (100,)"
     ]
    }
   ],
   "source": [
    "print(epoch, len(mse_train))\n",
    "plt.plot(np.arange(epoch + 1), mse_train)\n",
    "plt.plot(np.arange(epoch + 1), mse_test)  \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}